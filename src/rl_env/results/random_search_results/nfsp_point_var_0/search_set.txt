env_name_cego_game_judge_by_points_0_seed_12_game_variant_standard_game_activate_heuristic_True_game_train_players_[True, True, True, True]_hidden_layers_sizes_[512, 512]_reservoir_buffer_capacity_50000_anticipatory_param_0.2_batch_size_128_train_every_1_rl_learning_rate_1e-05_sl_learning_rate_0.001_min_buffer_size_to_learn_100_q_replay_memory_size_100000_q_replay_memory_init_size_100_q_update_target_estimator_every_10000_q_discount_factor_0.95_q_epsilon_start_1_q_epsilon_end_0.1_q_epsilon_decay_steps_50000_q_batch_size_32_q_train_every_1_q_mlp_layer_[512, 512]_num_eval_games_1000_num_episodes_50000_evaluate_every_500_
env_name_cego_game_judge_by_points_0_seed_12_game_variant_standard_game_activate_heuristic_True_game_train_players_[True, True, True, True]_hidden_layers_sizes_[128, 128]_reservoir_buffer_capacity_200000_anticipatory_param_0.1_batch_size_32_train_every_1_rl_learning_rate_1e-05_sl_learning_rate_5e-05_min_buffer_size_to_learn_100_q_replay_memory_size_100000_q_replay_memory_init_size_100_q_update_target_estimator_every_10000_q_discount_factor_0.95_q_epsilon_start_1_q_epsilon_end_0.1_q_epsilon_decay_steps_50000_q_batch_size_32_q_train_every_1_q_mlp_layer_[512, 512]_num_eval_games_1000_num_episodes_50000_evaluate_every_500_
env_name_cego_game_judge_by_points_0_seed_12_game_variant_standard_game_activate_heuristic_True_game_train_players_[True, True, True, True]_hidden_layers_sizes_[256, 256]_reservoir_buffer_capacity_100000_anticipatory_param_0.35_batch_size_32_train_every_1_rl_learning_rate_1e-05_sl_learning_rate_5e-05_min_buffer_size_to_learn_100_q_replay_memory_size_100000_q_replay_memory_init_size_100_q_update_target_estimator_every_10000_q_discount_factor_0.95_q_epsilon_start_1_q_epsilon_end_0.1_q_epsilon_decay_steps_50000_q_batch_size_32_q_train_every_1_q_mlp_layer_[512, 512]_num_eval_games_1000_num_episodes_50000_evaluate_every_500_
env_name_cego_game_judge_by_points_0_seed_12_game_variant_standard_game_activate_heuristic_True_game_train_players_[True, True, True, True]_hidden_layers_sizes_[512, 512]_reservoir_buffer_capacity_20000_anticipatory_param_0.25_batch_size_128_train_every_1_rl_learning_rate_1e-05_sl_learning_rate_5e-06_min_buffer_size_to_learn_100_q_replay_memory_size_100000_q_replay_memory_init_size_100_q_update_target_estimator_every_10000_q_discount_factor_0.95_q_epsilon_start_1_q_epsilon_end_0.1_q_epsilon_decay_steps_50000_q_batch_size_32_q_train_every_1_q_mlp_layer_[512, 512]_num_eval_games_1000_num_episodes_50000_evaluate_every_500_
env_name_cego_game_judge_by_points_0_seed_12_game_variant_standard_game_activate_heuristic_True_game_train_players_[True, True, True, True]_hidden_layers_sizes_[256, 256]_reservoir_buffer_capacity_20000_anticipatory_param_0.1_batch_size_32_train_every_1_rl_learning_rate_1e-05_sl_learning_rate_0.001_min_buffer_size_to_learn_100_q_replay_memory_size_100000_q_replay_memory_init_size_100_q_update_target_estimator_every_10000_q_discount_factor_0.95_q_epsilon_start_1_q_epsilon_end_0.1_q_epsilon_decay_steps_50000_q_batch_size_32_q_train_every_1_q_mlp_layer_[512, 512]_num_eval_games_1000_num_episodes_50000_evaluate_every_500_
env_name_cego_game_judge_by_points_0_seed_12_game_variant_standard_game_activate_heuristic_True_game_train_players_[True, True, True, True]_hidden_layers_sizes_[512, 512]_reservoir_buffer_capacity_100000_anticipatory_param_0.5_batch_size_32_train_every_1_rl_learning_rate_1e-05_sl_learning_rate_0.0001_min_buffer_size_to_learn_100_q_replay_memory_size_100000_q_replay_memory_init_size_100_q_update_target_estimator_every_10000_q_discount_factor_0.95_q_epsilon_start_1_q_epsilon_end_0.1_q_epsilon_decay_steps_50000_q_batch_size_32_q_train_every_1_q_mlp_layer_[512, 512]_num_eval_games_1000_num_episodes_50000_evaluate_every_500_
env_name_cego_game_judge_by_points_0_seed_12_game_variant_standard_game_activate_heuristic_True_game_train_players_[True, True, True, True]_hidden_layers_sizes_[256, 256]_reservoir_buffer_capacity_20000_anticipatory_param_0.2_batch_size_32_train_every_1_rl_learning_rate_1e-05_sl_learning_rate_1e-05_min_buffer_size_to_learn_100_q_replay_memory_size_100000_q_replay_memory_init_size_100_q_update_target_estimator_every_10000_q_discount_factor_0.95_q_epsilon_start_1_q_epsilon_end_0.1_q_epsilon_decay_steps_50000_q_batch_size_32_q_train_every_1_q_mlp_layer_[512, 512]_num_eval_games_1000_num_episodes_50000_evaluate_every_500_
env_name_cego_game_judge_by_points_0_seed_12_game_variant_standard_game_activate_heuristic_True_game_train_players_[True, True, True, True]_hidden_layers_sizes_[128, 128]_reservoir_buffer_capacity_20000_anticipatory_param_0.1_batch_size_32_train_every_1_rl_learning_rate_1e-05_sl_learning_rate_5e-06_min_buffer_size_to_learn_100_q_replay_memory_size_100000_q_replay_memory_init_size_100_q_update_target_estimator_every_10000_q_discount_factor_0.95_q_epsilon_start_1_q_epsilon_end_0.1_q_epsilon_decay_steps_50000_q_batch_size_32_q_train_every_1_q_mlp_layer_[512, 512]_num_eval_games_1000_num_episodes_50000_evaluate_every_500_
env_name_cego_game_judge_by_points_0_seed_12_game_variant_standard_game_activate_heuristic_True_game_train_players_[True, True, True, True]_hidden_layers_sizes_[512, 512, 512]_reservoir_buffer_capacity_50000_anticipatory_param_0.2_batch_size_64_train_every_1_rl_learning_rate_1e-05_sl_learning_rate_5e-06_min_buffer_size_to_learn_100_q_replay_memory_size_100000_q_replay_memory_init_size_100_q_update_target_estimator_every_10000_q_discount_factor_0.95_q_epsilon_start_1_q_epsilon_end_0.1_q_epsilon_decay_steps_50000_q_batch_size_32_q_train_every_1_q_mlp_layer_[512, 512]_num_eval_games_1000_num_episodes_50000_evaluate_every_500_
env_name_cego_game_judge_by_points_0_seed_12_game_variant_standard_game_activate_heuristic_True_game_train_players_[True, True, True, True]_hidden_layers_sizes_[512, 512]_reservoir_buffer_capacity_50000_anticipatory_param_0.2_batch_size_128_train_every_1_rl_learning_rate_1e-05_sl_learning_rate_1e-05_min_buffer_size_to_learn_100_q_replay_memory_size_100000_q_replay_memory_init_size_100_q_update_target_estimator_every_10000_q_discount_factor_0.95_q_epsilon_start_1_q_epsilon_end_0.1_q_epsilon_decay_steps_50000_q_batch_size_32_q_train_every_1_q_mlp_layer_[512, 512]_num_eval_games_1000_num_episodes_50000_evaluate_every_500_
env_name_cego_game_judge_by_points_0_seed_12_game_variant_standard_game_activate_heuristic_True_game_train_players_[True, True, True, True]_hidden_layers_sizes_[512, 512]_reservoir_buffer_capacity_50000_anticipatory_param_0.1_batch_size_32_train_every_1_rl_learning_rate_1e-05_sl_learning_rate_5e-05_min_buffer_size_to_learn_100_q_replay_memory_size_100000_q_replay_memory_init_size_100_q_update_target_estimator_every_10000_q_discount_factor_0.95_q_epsilon_start_1_q_epsilon_end_0.1_q_epsilon_decay_steps_50000_q_batch_size_32_q_train_every_1_q_mlp_layer_[512, 512]_num_eval_games_1000_num_episodes_50000_evaluate_every_500_
env_name_cego_game_judge_by_points_0_seed_12_game_variant_standard_game_activate_heuristic_True_game_train_players_[True, True, True, True]_hidden_layers_sizes_[256, 256]_reservoir_buffer_capacity_100000_anticipatory_param_0.2_batch_size_64_train_every_1_rl_learning_rate_1e-05_sl_learning_rate_5e-05_min_buffer_size_to_learn_100_q_replay_memory_size_100000_q_replay_memory_init_size_100_q_update_target_estimator_every_10000_q_discount_factor_0.95_q_epsilon_start_1_q_epsilon_end_0.1_q_epsilon_decay_steps_50000_q_batch_size_32_q_train_every_1_q_mlp_layer_[512, 512]_num_eval_games_1000_num_episodes_50000_evaluate_every_500_
env_name_cego_game_judge_by_points_0_seed_12_game_variant_standard_game_activate_heuristic_True_game_train_players_[True, True, True, True]_hidden_layers_sizes_[128, 128]_reservoir_buffer_capacity_200000_anticipatory_param_0.2_batch_size_128_train_every_1_rl_learning_rate_1e-05_sl_learning_rate_5e-06_min_buffer_size_to_learn_100_q_replay_memory_size_100000_q_replay_memory_init_size_100_q_update_target_estimator_every_10000_q_discount_factor_0.95_q_epsilon_start_1_q_epsilon_end_0.1_q_epsilon_decay_steps_50000_q_batch_size_32_q_train_every_1_q_mlp_layer_[512, 512]_num_eval_games_1000_num_episodes_50000_evaluate_every_500_
env_name_cego_game_judge_by_points_0_seed_12_game_variant_standard_game_activate_heuristic_True_game_train_players_[True, True, True, True]_hidden_layers_sizes_[128, 128]_reservoir_buffer_capacity_50000_anticipatory_param_0.1_batch_size_32_train_every_1_rl_learning_rate_1e-05_sl_learning_rate_0.0001_min_buffer_size_to_learn_100_q_replay_memory_size_100000_q_replay_memory_init_size_100_q_update_target_estimator_every_10000_q_discount_factor_0.95_q_epsilon_start_1_q_epsilon_end_0.1_q_epsilon_decay_steps_50000_q_batch_size_32_q_train_every_1_q_mlp_layer_[512, 512]_num_eval_games_1000_num_episodes_50000_evaluate_every_500_
env_name_cego_game_judge_by_points_0_seed_12_game_variant_standard_game_activate_heuristic_True_game_train_players_[True, True, True, True]_hidden_layers_sizes_[256, 256]_reservoir_buffer_capacity_100000_anticipatory_param_0.1_batch_size_128_train_every_1_rl_learning_rate_1e-05_sl_learning_rate_5e-05_min_buffer_size_to_learn_100_q_replay_memory_size_100000_q_replay_memory_init_size_100_q_update_target_estimator_every_10000_q_discount_factor_0.95_q_epsilon_start_1_q_epsilon_end_0.1_q_epsilon_decay_steps_50000_q_batch_size_32_q_train_every_1_q_mlp_layer_[512, 512]_num_eval_games_1000_num_episodes_50000_evaluate_every_500_
env_name_cego_game_judge_by_points_0_seed_12_game_variant_standard_game_activate_heuristic_True_game_train_players_[True, True, True, True]_hidden_layers_sizes_[512, 512]_reservoir_buffer_capacity_20000_anticipatory_param_0.1_batch_size_32_train_every_1_rl_learning_rate_1e-05_sl_learning_rate_0.0001_min_buffer_size_to_learn_100_q_replay_memory_size_100000_q_replay_memory_init_size_100_q_update_target_estimator_every_10000_q_discount_factor_0.95_q_epsilon_start_1_q_epsilon_end_0.1_q_epsilon_decay_steps_50000_q_batch_size_32_q_train_every_1_q_mlp_layer_[512, 512]_num_eval_games_1000_num_episodes_50000_evaluate_every_500_
env_name_cego_game_judge_by_points_0_seed_12_game_variant_standard_game_activate_heuristic_True_game_train_players_[True, True, True, True]_hidden_layers_sizes_[512, 512, 512]_reservoir_buffer_capacity_100000_anticipatory_param_0.1_batch_size_32_train_every_1_rl_learning_rate_1e-05_sl_learning_rate_0.0001_min_buffer_size_to_learn_100_q_replay_memory_size_100000_q_replay_memory_init_size_100_q_update_target_estimator_every_10000_q_discount_factor_0.95_q_epsilon_start_1_q_epsilon_end_0.1_q_epsilon_decay_steps_50000_q_batch_size_32_q_train_every_1_q_mlp_layer_[512, 512]_num_eval_games_1000_num_episodes_50000_evaluate_every_500_
env_name_cego_game_judge_by_points_0_seed_12_game_variant_standard_game_activate_heuristic_True_game_train_players_[True, True, True, True]_hidden_layers_sizes_[512, 512, 512]_reservoir_buffer_capacity_50000_anticipatory_param_0.25_batch_size_64_train_every_1_rl_learning_rate_1e-05_sl_learning_rate_1e-05_min_buffer_size_to_learn_100_q_replay_memory_size_100000_q_replay_memory_init_size_100_q_update_target_estimator_every_10000_q_discount_factor_0.95_q_epsilon_start_1_q_epsilon_end_0.1_q_epsilon_decay_steps_50000_q_batch_size_32_q_train_every_1_q_mlp_layer_[512, 512]_num_eval_games_1000_num_episodes_50000_evaluate_every_500_
env_name_cego_game_judge_by_points_0_seed_12_game_variant_standard_game_activate_heuristic_True_game_train_players_[True, True, True, True]_hidden_layers_sizes_[128, 128]_reservoir_buffer_capacity_20000_anticipatory_param_0.1_batch_size_32_train_every_1_rl_learning_rate_1e-05_sl_learning_rate_1e-05_min_buffer_size_to_learn_100_q_replay_memory_size_100000_q_replay_memory_init_size_100_q_update_target_estimator_every_10000_q_discount_factor_0.95_q_epsilon_start_1_q_epsilon_end_0.1_q_epsilon_decay_steps_50000_q_batch_size_32_q_train_every_1_q_mlp_layer_[512, 512]_num_eval_games_1000_num_episodes_50000_evaluate_every_500_
env_name_cego_game_judge_by_points_0_seed_12_game_variant_standard_game_activate_heuristic_True_game_train_players_[True, True, True, True]_hidden_layers_sizes_[512, 512, 512]_reservoir_buffer_capacity_100000_anticipatory_param_0.35_batch_size_128_train_every_1_rl_learning_rate_1e-05_sl_learning_rate_5e-05_min_buffer_size_to_learn_100_q_replay_memory_size_100000_q_replay_memory_init_size_100_q_update_target_estimator_every_10000_q_discount_factor_0.95_q_epsilon_start_1_q_epsilon_end_0.1_q_epsilon_decay_steps_50000_q_batch_size_32_q_train_every_1_q_mlp_layer_[512, 512]_num_eval_games_1000_num_episodes_50000_evaluate_every_500_
